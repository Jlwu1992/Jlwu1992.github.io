<!DOCTYPE html>
<!--[if IE 8]> 
<html lang="en" class="ie8">
   <![endif]-->
   <!--[if IE 9]> 
   <html lang="en" class="ie9">
      <![endif]-->
      <!--[if !IE]><!--> 
      <html lang="en">
         <!--<![endif]-->
         <head>
            <title>Jianlong Wu</title>
            <!-- Meta -->
            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1">
            <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
            <meta name="description" content="Jianlong Wu's homepage">
            <link rel="shortcut icon" href="assets/images/log.png">
            <link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
            <!-- Global CSS -->
            <link rel="stylesheet" href="assets/css/bootstrap.min.css">
            <link rel="stylesheet" href="assets/css/font-awesome/css/font-awesome.min.css">
            <link rel="stylesheet" href="assets/css/main.css">
            <script src="bootstrap/js/bootstrap.min.js"></script>
            <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
            <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
            <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
            <![endif]-->
            <script>
               (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
               (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
               m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
               })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
               
               ga('create', 'UA-88572407-1', 'auto');
               ga('send', 'pageview');
            </script>
         </head>
         <body>
            <div class="container">
            <div class="row">
               <div class='row'>
                  <div class='col-xs-3'>
                     <div class='photo'>
                        <img src="assets/images/jlwu.jpg" alt="photo"/>
                     </div>
                  </div>
                  <div class='col-xs-8'>
                     <h3>
                        Jianlong Wu (吴建龙)
                     </h3>
                     <p>
					 <p>
					 <p>
                        I'm Jianlong Wu, a professor and doctoral advisor in <a href="http://cs.hitsz.edu.cn/">School of Computer Science and Technology</a>, <a href="https://www.hitsz.edu.cn/">Harbin Institute of Technology(Shenzhen)</a>. I worked as an assistant professor in Shandong University from 2019 to 2022. I received my Ph.D. degree in computer vision from the <a href="https://zero-lab-pku.github.io/">ZERO Lab</a>,  <a href="http://eecs.pku.edu.cn/">School of Electronics Engineering and Computer Science</a>, <a href="https://www.pku.edu.cn/">Peking University</a> in 2019, advised by Professor <a href="https://zhouchenlin.github.io/">Zhouchen Lin</a> (IEEE Fellow) and Professor <a href="https://www.cis.pku.edu.cn/info/1177/1379.htm">Hongbin Zha</a>. In 2014, I received my bachelor's degree in electronics and information engineering from the advanced class,  <a href="https://www.hust.edu.cn/">Huazhong University of Science and Technology (HUST)</a>.  
                     </p>
                     </p>
					 <div class='researchInt'>
                     <h3 style="padding-top:-300px">Research Interest</h3>
                     <p>Computer Vision, Multi-modal Learning. </p>
                     </div>
					 <p>
                     <h3 style="padding-top:-200px"></h3>
                     <a href="mailto: wujianlong@hit.edu.cn"><i class="fa fa-envelope"></i> &nbsp; wujianlong@hit.edu.cn</a>
                     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
                     <a href="https://scholar.google.com/citations?user=XGeEH-IAAAAJ&hl=zh-CN" target="_blank"><i class="fa fa-globe"></i> &nbsp; Google Scholar</a>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
                     <a href="https://faculty.hitsz.edu.cn/wujianlong" target="_blank"><i class="fa fa-paper-plane"></i> &nbsp; 中文简介</a>
                  </div>
               </div>
               <hr>
			   <h3>
                  <a name='recuit'></a> Recruit
               </h3>
               <div class='masters'>
				  I'm recruiting <strong>self-motivated postdoctoral fellow, Ph.D. and master students</strong> who have strong mathematical abilities and coding skills to work with me on multimodal learning related research topics. Welcome to send me your detailed resume!</p>
               </div>
               <hr>
               <h3>
                  <a name='publications'></a> News
               </h3>
               <div class='news'>
                  <ul>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2024/10] I will serve as an Area Chair of CVPR 2025 and ICML 2025. Several papers were accepted by ECCV, ACM MM, and NeurIPS. </li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2024/03] I will serve as an Area Chair of NeurIPS 2024 and ACM MM 2024. Two papers were accepted by TPAMI. </li>
					<li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2023/12] Won the First Prize of Shandong Provincial Technological Invention Award and the Young Elite Scientists Sponsorship Program by CAST.  </li>
					 <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2023/08] Three papers were accepted by ACM MM. </li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2023/05] I will serve as an Area Chair of ACM Multimedia 2023. Two papers were accepted by ACL and SIGIR, respectively. </li>
					 <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2023/03] I will serve as an Area Chair of NeurIPS 2023 and a Guest Editor of TCSVT. Two papers were accepted by CVPR and TIP, respectively. </li>
					 <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2022/07] Three papers were accepted by TNNLS, ECCV 2022, and ACM MM 2022, respectively.</li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2022/02] Two papers were accepted by CVPR 2022 and three papers were accepted by IEEE Trans. Multimedia.</li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2021/12] Our work won the First Prize of the Shandong Provincial Science and Technology Progress Award in 2021.</li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2021/07] Our paper received the Best Student Paper Award of SIGIR 2021. And one paper was accepted by ICCV 2021.</li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2021/04] One paper was accepted by PR and another paper was accepted by SIGIR 2021.</li>
					 <!--<li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2020/10] I will serve as a Senior Program Committee (SPC) Member for IJCAI 2021.</li>-->
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2020/09] Four papers were accepted by NeurIPS 2020, ICML 2020, SIGIR 2020, and ECCV 2020, respectively.</li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2019/11] Three papers were accepted by AAAI 2020.</li>
				     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2019/07] Two papers were accepted by ICCV 2019 with one oral presentation.</li>
                     <li><i class="fa fa-flag"  color="#FF0000"
                        aria-hidden="true"></i>[2019/05] Two papers were accepted by IEEE Trans. Image Processing and ICML 2019.</li>
                  </ul>
               </div>
               <hr>
               <h3>
                  <a name='publications'></a> Publications 
               </h3>
			   (* denotes equal contributions and ^ denotes corresponding author)
			   <h4>
					<a name='2025'></a> Preprint
               </h4>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Video DataFlywheel: Resolving the Impossible Data Trinity in Video-Language Understanding</strong><br />
                        Xiao Wang, <strong>Jianlong Wu^</strong>, Zijia Lin, Fuzheng Zhang, Di Zhang, Liqiang Nie^<br />
						<a href="https://arxiv.org/abs/2409.19532">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Mamba-FSCIL: Dynamic Adaptation with Selective State Space Model for Few-Shot Class-Incremental Learning</strong><br />
                        Xiaojie Li, Yibo Yang, <strong>Jianlong Wu^</strong>, Bernard Ghanem, Liqiang Nie, Min Zhang<br />
						<a href="https://arxiv.org/abs/2407.06136">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training</strong><br />
                        Muhe Ding, Yang Ma, Pengda Qin, <strong>Jianlong Wu^</strong>, Yuhong Li, Liqiang Nie<br />
						<a href="https://arxiv.org/abs/2410.14154">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <h4>
					<a name='2024'></a> 2024
               </h4>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>GenView: Enhancing View Quality with Pretrained Generative Model for Self-supervised Learning</strong><br />
                        Xiaojie Li, Yibo Yang^, Xiangtai Li, <strong>Jianlong Wu^</strong>, Yue Yu, Bernard Ghanem, Min Zhang<br />
                        European Conference on Computer Vision (<strong>ECCV</strong>), 2024 <br />
						<a href="https://link.springer.com/chapter/10.1007/978-3-031-73113-6_18">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Differential-Perceptive and Retrieval-Augmented MLLM for Change Captioning</strong><br />
                        Xian Zhang, Haokun Wen, <strong>Jianlong Wu^</strong>, Pengda Qin, Hui Xue, Liqiang Nie^ <br />
                        ACM Conference on Multimedia (<strong>ACM MM</strong>), 2024 <br />
						<a href="https://dl.acm.org/doi/10.1145/3664647.3681453">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>CorDA: Context-oriented Decomposition Adaptation of Large Language Models</strong><br />
                        Yibo Yang, Xiaojie Li, Zhongzhu Zhou, Shuaiwen Leon Song, <strong>Jianlong Wu</strong>, Liqiang Nie, Bernard Ghanem <br />
                        Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024 <br />
						<a href="https://arxiv.org/abs/2406.05223">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Detecting and Grounding Multi-modal Media Manipulation and Beyond</strong><br />
                        Rui Shao, Tianxing Wu, <strong>Jianlong Wu</strong>, Liqiang Nie, Ziwei Liu<br />
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2024<br />
						<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440475">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Self-Training Boosted Multi-Factor Matching Network for Composed Image Retrieval</strong><br />
                        Haokun Wen, Xuemeng Song, Jianhua Yin, <strong>Jianlong Wu</strong>, Weili Guan, Liqiang Nie<br />
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2024<br />
						<a href="https://ieeexplore.ieee.org/abstract/document/10373096">[PDF]</a> 
                     </p>
                  </div>
			   </div>
                    <a name='2023'></a> 2023
               </h4>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Neighbor-guided Consistent and Contrastive Learning for Semi-supervised Action Recognition</strong><br />
                        <strong>Jianlong Wu</strong>, Wei Sun, Tian Gan, Ning Ding, Feijun Jiang, Jialie Shen, Liqiang Nie<br />
                        IEEE Transactions on Image Processing (<strong>TIP</strong>), 2023<br />
						<a href="https://ieeexplore.ieee.org/document/10100655">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>CHMATCH: Contrastive Hierarchical Matching and Robust Adaptive Threshold Boosted Semi-Supervised Learning</strong><br />
                        <strong>Jianlong Wu</strong>, Haozhe Yang, Tian Gan, Ning Ding, Feijun Jiang, Liqiang Nie<br />
                        IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023<br />
						<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_CHMATCH_Contrastive_Hierarchical_Matching_and_Robust_Adaptive_Threshold_Boosted_Semi-Supervised_CVPR_2023_paper.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Self-adaptive Context and Modal-interaction Modeling For Multimodal Emotion Recognition</strong><br />
                        Haozhe Yang, Xianqiang Gao, <strong>Jianlong Wu^</strong>, Tian Gan, Ning Ding, Feijun Jiang, Liqiang Nie<br />
                        Findings of the Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2023<br />
						<a href="https://aclanthology.org/2023.findings-acl.390/">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Fine-grained Key-Value Memory Enhanced Predictor for Video Representation Learning</strong><br />
                        Xiaojie Li, <strong>Jianlong Wu^</strong>, Shaowei He, Kang Shuo, Yue Yu, Liqiang Nie, Min Zhang<br />
                        ACM Conference on Multimedia (<strong>ACM MM</strong>), 2023<br />
						<a href="https://dl.acm.org/doi/10.1145/3581783.3612131">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Temporal Sentence Grounding in Streaming Videos</strong><br />
                        Tian Gan, Xiao Wang, Yan Sun, <strong>Jianlong Wu^</strong>, Qingpei Guo, Liqiang Nie<br />
                        ACM Conference on Multimedia (<strong>ACM MM</strong>), 2023<br />
						<a href="https://dl.acm.org/doi/10.1145/3581783.3612120">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Mask Again: Masked Knowledge Distillation for Masked Video Modeling</strong><br />
                        Xiaojie Li, Shaowei He, <strong>Jianlong Wu^</strong>, Yue Yu, Liqiang Nie^, Min Zhang<br />
                        ACM Conference on Multimedia (<strong>ACM MM</strong>), 2023<br />
						<a href="https://dl.acm.org/doi/10.1145/3581783.3612129">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Semantic-aware Modular Capsule Routing for Visual Question Answering</strong><br />
                        Yudong Han, Jianhua Yin, <strong>Jianlong Wu</strong>, Yinwei Wei, Liqiang Nie<br />
                        IEEE Transactions on Image Processing (<strong>TIP</strong>), 2023<br />
						<a href="https://ieeexplore.ieee.org/document/10268338">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>SNP-S3: Shared Network Pre-training and Significant Semantic Strengthening for Various Video-Text Tasks</strong><br />
                        Xingning Dong, Qingpei Guo, Tian Gan, Qing Wang, <strong>Jianlong Wu</strong>, Xiangyuan Ren, Yuan Cheng, Wei Chu<br />
                        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2023<br />
						<a href="https://ieeexplore.ieee.org/document/10214396">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Multi-Granularity Interaction and Integration Network for Video Question Answering</strong><br />
                        Yuanyuan Wang, Meng Liu, <strong>Jianlong Wu</strong>, Liqiang Nie<br />
                        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2023<br />
						<a href="https://ieeexplore.ieee.org/document/10130300">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification</strong><br />
                        Dengtian Lin, Yang Ma, Yuhong Li, Xuemeng Song, <strong>Jianlong Wu</strong>, Liqiang Nie<br />
                        Industrial Track of the International ACM SIGIR Conference on Research and Development in Information Retrieval (<strong>SIGIR</strong>), 2023<br />
						<a href="https://dl.acm.org/doi/10.1145/3539618.3591864">[PDF]</a>
                     </p>
                  </div>
               </div>
			   <h4>
                    <a name='2022'></a> 2022
               </h4>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Micro-video Tagging via Jointly Modeling Social Influence and Tag Relation</strong><br />
                        Xiao Wang, Tian Gan^, Yinwei Wei, <strong>Jianlong Wu^</strong>, Xiaoqiang Lei, Liqiang Nie<br />
                        ACM Conference on Multimedia (<strong>ACM MM</strong>), 2022<br />
						<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548098">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>HEAD: HEtero-Assists Distillation for Heterogeneous Object Detectors</strong><br />
                        Luting Wang, Xiaojie Li, Yue Liao, Zeren Jiang, <strong>Jianlong Wu</strong>, Fei Wang, Chen Qian, Si Liu<br />
                        European Conference on Computer Vision (<strong>ECCV</strong>), 2022 <br />
						<a href="https://arxiv.org/abs/2207.05345">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>TryonCM2: Try-on-Enhanced Fashion Compatibility Modeling Framework</strong><br />
                        Xue Dong, Xuemeng Song, Na Zheng, <strong>Jianlong Wu</strong>, Hongjun Dai, Liqiang Nie<br />
                        IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), 2022<br />
						<a href="https://ieeexplore.ieee.org/abstract/document/9775146/">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation</strong><br />
                        Xingning Dong, Tian Gan, Xuemeng Song, <strong>Jianlong Wu</strong>, Yuan Cheng, Liqiang Nie<br />
                        IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022<br />
						<a href="https://arxiv.org/abs/2203.09811">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>High Quality Segmentation for Ultra High-resolution Images</strong><br />
                        Tiancheng Shen, Yuechen Zhang, Lu Qi, Jason Kuen, Xingyu Xie, <strong>Jianlong Wu</strong>, Zhe Lin, Jiaya Jia<br />
                        IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022<br />
						<a href="https://arxiv.org/abs/2111.14482">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Self-supervised Correlation Learning for Cross-Modal Retrieval</strong><br />
                        Yaxin Liu, <strong>Jianlong Wu^</strong>, Leigang Qu, Tian Gan, Jianhua Yin, Liqiang Nie<br />
                        IEEE Transactions on Multimedia (<strong>TMM</strong>), 2022<br />
						<a href="https://ieeexplore.ieee.org/abstract/document/9714824/">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Micro-influencer Recommendation by Multi-perspective Account Representation Learning</strong><br />
                        Shaokun Wang, Tian Gan^, Yuan Liu, <strong>Jianlong Wu^</strong>, Yuan Cheng, Liqiang Nie<br />
                        IEEE Transactions on Multimedia (<strong>TMM</strong>), 2022<br />
						<a href="https://ieeexplore.ieee.org/abstract/document/9712372/">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>DualGNN: Dual Graph Neural Network for Multimedia Recommendation</strong><br />
                        Qifan Wang, Yinwei Wei, Jianhua Yin, <strong>Jianlong Wu</strong>, Xuemeng Song, Liqiang Nie<br />
                        IEEE Transactions on Multimedia (<strong>TMM</strong>), 2022<br />
						<a href="https://ieeexplore.ieee.org/abstract/document/9662655/">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <h4>
                    <a name='2021'></a> 2021
               </h4>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Graph Contrastive Clustering</strong><br />
                        Huasong Zhong*, <strong>Jianlong Wu*</strong>, Chong Chen, Jianqiang Huang, Minghua Deng, Liqiang Nie, Zhouchen Lin, Xiansheng Hua<br />
                        International Conference on Computer Vision (<strong>ICCV</strong>), 2021<br />
						<a href="https://arxiv.org/pdf/2104.01429.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Reconstruction Regularized Low-Rank Subspace Learning for Cross-Modal Retrieval</strong><br />
                        <strong>Jianlong Wu</strong>, Xingyu Xie, Liqiang Nie, Zhouchen Lin, Hongbin Zha<br />
                        Pattern Recognition (<strong>PR</strong>), 2021<br />
						<a href="https://www.sciencedirect.com/science/article/pii/S0031320320306166">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Dynamic Modality Interaction Modeling for Image-Text Retrieval</strong><br />
                        Leigang Qu, Meng Liu, <strong>Jianlong Wu</strong>, Zan Gao, Liqiang Nie	<br />
                        International ACM SIGIR Conference on Research and Development in Information Retrieval (<strong>SIGIR, Best Student Paper</strong>), 2021<br />
						<a href="https://dl.acm.org/doi/abs/10.1145/3404835.3462829">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Discover Micro-influencers for Brands via Better Understanding</strong><br />
                        Shaokun Wang, Tian Gan, Yuan Liu, Li Zhang, <strong>Jianlong Wu</strong>, Liqiang Nie<br />
                        IEEE Transactions on Multimedia (<strong>TMM</strong>), 2021<br />
						<a href="https://ieeexplore.ieee.org/abstract/document/9454334">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <h4>
                    <a name='2020'></a> 2020
               </h4>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Agree to Disagree: Adaptive Ensemble Knowledge Distillation in Gradient Space</strong><br />
                        Shangchen Du*, Shan You*^, Xiaojie Li, <strong>Jianlong Wu^</strong>, Fei Wang, Chen Qian, Changshui Zhang<br />
                        Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2020 <br />
						<a href="https://proceedings.neurips.cc/paper/2020/file/91c77393975889bd08f301c9e13a44b7-Paper.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Local Correlation Consistency for Knowledge Distillation</strong><br />
                        Xiaojie Li, <strong>Jianlong Wu^</strong>, Hongyu Fang, Yue Liao, Fei Wang, Chen Qian<br />
                        European Conference on Computer Vision (<strong>ECCV</strong>), 2020 <br />
						<a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570018.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Maximum-and-Concatenation Networks</strong><br />
                        Xingyu Xie, Hao Kong, <strong>Jianlong Wu</strong>, Wayne Zhang, Guangcan Liu, Zhouchen Lin<br />
                        International Conference on Machine Learning (<strong>ICML</strong>), 2020<br />
						<a href="https://arxiv.org/abs/2007.04630">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Fashion Compatibility Modeling through a Multi-modal Try-on-guided Scheme</strong><br />
                        Xue Dong, <strong>Jianlong Wu</strong>, Xuemeng Song, Hongjun Dai, Liqiang Nie<br />
                        International ACM SIGIR Conference on Research and Development in Information Retrieval (<strong>SIGIR</strong>), 2020<br />
						<a href="https://dl.acm.org/doi/abs/10.1145/3397271.3401047">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Unified Graph and Low-rank Tensor Learning for Multi-view Clustering</strong><br />
                        <strong>Jianlong Wu*</strong>, Xingyu Xie*, Liqiang Nie, Zhouchen Lin, Hongbin Zha<br />
                        AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020<br /> 
						<a href="https://aaai.org/ojs/index.php/AAAI/article/view/6109">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families</strong><br />
                        Yibo Yang*, <strong>Jianlong Wu*</strong>, Hongyang Li, Xia Li, Tiancheng Shen, Zhouchen Lin<br />
                        AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020<br />
						<a href="https://aaai.org/ojs/index.php/AAAI/article/view/6141">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>SOGNet: Scene Overlap Graph Network for Panoptic Segmentation</strong><br />
                        Yibo Yang*, Hongyang Li*, Xia Li, Qijie Zhao, <strong>Jianlong Wu</strong>, Zhouchen Lin<br />
                        AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020<br />
						<a href="https://arxiv.org/abs/1911.07527">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <h4>
                    <a name='2019'></a> 2019
               </h4>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Deep Comprehensive Correlation Mining for Image Clustering</strong><br />
                        <strong>Jianlong Wu*</strong>, Keyu Long*, Fei Wang, Chen Qian, Cheng Li, Zhouchen Lin, Hongbin Zha<br />
                        International Conference on Computer Vision (<strong>ICCV</strong>), 2019<br />
						<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Deep_Comprehensive_Correlation_Mining_for_Image_Clustering_ICCV_2019_paper.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Expectation-Maximization Attention Networks for Semantic Segmentation</strong><br />
                        Xia Li, Zhisheng Zhong, <strong>Jianlong Wu</strong>, Yibo Yang, Zhouchen Lin, Hong Liu<br />
                        International Conference on Computer Vision (<strong>ICCV, Oral</strong>), 2019<br />
						<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Expectation-Maximization_Attention_Networks_for_Semantic_Segmentation_ICCV_2019_paper.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Essential Tensor Learning for Multi-view Spectral Clustering</strong><br />
                        <strong>Jianlong Wu</strong>, Zhouchen Lin, Hongbin Zha<br />
                        IEEE Transactions on Image Processing (<strong>TIP</strong>), 2019<br />
						<a href="https://arxiv.org/pdf/1807.03602.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Differentiable Linearized ADMM</strong><br />
                        Xingyu Xie*, <strong>Jianlong Wu*</strong>, Zhisheng Zhong, Guangcan Liu, Zhouchen Lin<br />
                        International Conference on Machine Learning (<strong>ICML</strong>), 2019<br />
						<a href="http://proceedings.mlr.press/v97/xie19c/xie19c.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>   
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>R^2 -Net: Recurrent and Recursive Network for Sparse-view CT Artifacts Removal</strong><br />
                        Tiancheng Shen*, Xia Li*, Zhisheng Zhong, <strong>Jianlong Wu</strong>, Zhouchen Lin<br />
                        International Conference on Medical Image Computing and Computer Assisted Intervention (<strong>MICCAI</strong>), 2019<br />
						<a href="https://link.springer.com/chapter/10.1007/978-3-030-32226-7_36">[PDF]</a>
                     </p>
                  </div>
               </div>   			   
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Matrix Recovery With Implicitly Low-rank Data</strong><br />
                        Xingyu Xie, <strong>Jianlong Wu</strong>, Guangcan Liu, Jun Wang<br />
                        Neurocomputing, 2019<br />
						<a href="https://www.sciencedirect.com/science/article/pii/S0925231219300426">[PDF]</a>
                     </p>
                  </div>
               </div>
               <h4>
                    <a name='2018'></a> 2018
               </h4>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Recurrent Squeeze-and-Excitation Context Aggregation Net for Single Image Deraining</strong><br />
                        Xia Li*, <strong>Jianlong Wu*</strong>, Zhouchen Lin, Hong Liu, Hongbin Zha<br />
                        European Conference on Computer Vision (<strong>ECCV</strong>), 2018 <br />
						<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Xia_Li_Recurrent_Squeeze-and-Excitation_Context_ECCV_2018_paper.pdf">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Joint Dictionary Learning and Semantic Constrained Latent Subspace Projection for Cross-modal Retrieval</strong><br />
                        <strong>Jianlong Wu</strong>, Zhouchen Lin, Hongbin Zha<br />
                        ACM International Conference on Information and Knowledge Management  (<strong>CIKM</strong>, short paper), 2018 <br />
                        <a href="https://dl.acm.org/citation.cfm?id=3269296">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <h4>
                	<a name='2017'></a> 2017
               </h4>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Joint Latent Subspace Learning and Regression for Cross-modal Retrieval</strong><br />
                        <strong>Jianlong Wu</strong>, Zhouchen Lin, Hongbin Zha<br />
                        International ACM SIGIR Conference on Research and Development in Information Retrieval (<strong>SIGIR</strong>, short paper), 2017  <br />
                        <a href="https://dl.acm.org/citation.cfm?id=3080678">[PDF]</a> 
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Locality-constrained Linear Coding Based Bi-layer Model for Multi-view Facial Expression Recognition</strong><br />
                        <strong>Jianlong Wu</strong>, Zhouchen Lin, Wenming Zheng, Hongbin Zha<br />
                        Neurocomputing, 2017 <br />
                        <a href="https://www.sciencedirect.com/science/article/pii/S0925231217302825">[PDF]</a>
                     </p>
                  </div>
               </div>
               <h4>
                	<a name='2016'></a> 2016
               </h4>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Multi-view Common Space Learning for Emotion Recognition in the Wild</strong><br />
                        <strong>Jianlong Wu</strong>, Zhouchen Lin, Hongbin Zha<br />
                        ACM International Conference on Multimodal Interaction (<strong>ICMI</strong>), 2016<br />
                        <a href="https://dl.acm.org/citation.cfm?id=2997631">[PDF]</a>
                     </p>
                  </div>
               </div>
               <h4>
                	<a name='2015'></a> 2015
               </h4>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Multiple Models Fusion for Emotion Recognition in the Wild</strong><br />
                        <strong>Jianlong Wu</strong>, Zhouchen Lin, Hongbin Zha<br />
                        ACM International Conference on Multimodal Interaction (<strong>ICMI</strong>), 2015<br />
                        <a href="https://dl.acm.org/citation.cfm?id=2830582">[PDF]</a>
                     </p>
                  </div>
               </div>
			   			   <hr>
               <h3>
                  <a name='service'></a> Academic Services
               </h3>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Area Chair:</strong><br />
						International Conference on Machine Learning (<strong>ICML</strong>, 2025), IEEE Conference on Computer Vision and Pattern Recognition  (<strong>CVPR</strong>, 2025),Neural Information Processing Systems (<strong>NeurIPS</strong>, 2024/2023),
						ACM Multimedia (<strong>ACM MM</strong>, 2024/2023),
                        IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>, 2022/2020)
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Guest Editor:</strong><br />
						IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>),
                        International Journal of Multimedia Information Retrieval (<strong>IJMIR</strong>),
						Visual Intelligence
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Senior Program Committee (SPC) Member:</strong><br />
                        International Joint Conferences on Artificial Intelligence (<strong>IJCAI</strong>, 2023)
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Reviewer for Journals:</strong><br />
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), International Journal of Computer Vision (<strong>IJCV</strong>), IEEE Transactions on Image Processing (<strong>TIP</strong>), IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), Pattern Recognition (<strong>PR</strong>), IEEE Transactions on Multimedia (<strong>TMM</strong>), IEEE Transactions on Cybernetics (<strong>TCYB</strong>)
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Reviewer (or Program Committee Member) for Conferences:</strong><br />
						International Conference on Machine Learning (<strong>ICML</strong>), Neural Information Processing Systems (<strong>NeurIPS</strong>), IEEE Conference on Computer Vision and Pattern Recognition  (<strong>CVPR</strong>), International Conference on Computer Vision (<strong>ICCV</strong>), Eourpean Conference on Computer Vision (<strong>ECCV</strong>), AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), ACM Conference on Multimedia (<strong>ACM MM</strong>), International Conference on Learning Representation (<strong>ICLR</strong>), International Joint Conferences on Artificial Intelligence (<strong>IJCAI</strong>)
                     </p>
                  </div>
               </div>
               <hr>
               <h3>
                  <a name='publications'></a> Selected Awards
               </h3>
               <div class='award'>
                  <ul >
				     <li>2023 First Prize of the Shandong Provincial Technological Invention Award
				     <li>2023 Young Elite Scientists Sponsorship Program by CAST
					 <li>2022 Outstanding Young Scholar, Harbin Institute of Technology (Shenzhen)
				     <li>2021 First Prize of the Shandong Provincial Science and Technology Progress Award
				     <li>2021 Best Student Paper of SIGIR 2021
					 <li>2020 Future Program for Young Scholars, Shandong University
				     <li>2020 Top Reviewer of ICML 2020
				     <li>2019 Outstanding Graduate, Peking University
					 <li>2019 ICML Travel Award
                     <li>2018 National Scholarship for Ph.D. Student (Top 2% in PKU)
					 <li>2018 Pexpertmaker to Merit Student, Peking University
					 <li>2017 Merit Student, Peking University
                     <li>2016 Outstanding Academic Award, Peking University
                     <li>2014 Outstanding Graduate, HUST
                     <li>2014 Excellent Student Cadre, HUST
                  </ul>
               </div>
               <hr>
               <h3>
                  <a name='teaching'></a> Teaching
               </h3>
               <div class='teaching'>
                  <ul >
					 <li>Introduction to Object-Oriented Software Construction, Harbin Institute of Technology (Shenzhen), Spring 2024/2023.</li>
                     <li>Digital Image Processing, Shandong University, Fall 2021/2020/2019.</li>
					 <li>Advanced Language Programming, Shandong University, Spring 2022/2021/2020.</li>
                     <li>Computer Vision, Shandong University, Fall 2020/2019.</li>
                  </ul>
               </div>
            </div>
            </div>

            <!--//main-body-->
            <hr>
            <footer class="footer">
               <div class="container">
                  <small class="copyright"> 2024 Jianlong Wu</small>
               </div>
               <!--//container-->
            <!--/footer-->
            <!--//footer-->
            <!--div style="display:inline-block;width:200px;">
               <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5ekw1not1zt&amp;m=8&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=0" async="async"></script>
            </div-->
         </body>
      </html>